{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "aae.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "fb6FiTPn3XS8",
        "F3Bto5ZZ3pPI",
        "2b60cKeX30bT",
        "RJYW6gn64KRE"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/francesco-mannella/AdversarialWidhKeras/blob/master/aae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb6FiTPn3XS8",
        "colab_type": "text"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN0liLYxuWwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "%matplotlib inline\n",
        "\n",
        "from __future__ import division, print_function, absolute_import\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "seed = 1\n",
        "rng = np.random.RandomState(seed)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ca0WuCyfzbtr",
        "colab_type": "code",
        "outputId": "b45da30b-4f15-4ac5-b429-18352c7b3fa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (_, _) = mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_train = 2*x_train - 1\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sIZ5S03zvlW",
        "colab_type": "text"
      },
      "source": [
        "#Build the graph\n",
        "We build the Adversarial Autoencoder network. It is made of three networks: the encoder, the decoder and the discriminator.\n",
        "Those networks are combined to run \n",
        "* an autoencoder network (**images**->**encoder**->**latents**->**decoder**->**generated_images**)\n",
        "* a discriminator network (\n",
        "    * **latents**->**discriminator**->**D_Probs**\n",
        "    * **images**->**encoder**->**latents**->**discriminator**->**G_Propbs**\n",
        "    \n",
        "    )\n",
        "* a generator network (**images**->**encoder**->**latents**->**discriminator**->**G_Probs**)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ssk5nxwYzyzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "class Autoencoder:\n",
        "    def __init__(self, latent_num, dropout, w_stddev, autoencoder_rl, \n",
        "                 discriminator_rl, generator_rl):\n",
        "\n",
        "        self.autoencoder_optimizer = Adam(autoencoder_rl, 0.5)\n",
        "        self.discriminator_optimizer = Adam(discriminator_rl, 0.5)\n",
        "        self.generator_optimizer = Adam(generator_rl, 0.5)\n",
        "\n",
        "        def w_init(stddev):\n",
        "            return keras.initializers.RandomNormal(mean=0.0, stddev=stddev)\n",
        "\n",
        "        def dense(units, **kargs):\n",
        "            return keras.layers.Dense(\n",
        "                units=units,\n",
        "                kernel_initializer=w_init(w_stddev),\n",
        "                bias_initializer=w_init(w_stddev),\n",
        "                **kargs)\n",
        "\n",
        "        # encoder \n",
        "        self.encoder = keras.models.Sequential(name=\"encoder_net\")\n",
        "        self.encoder.add(keras.layers.Flatten())\n",
        "        self.encoder.add(dense(1024, name=\"dL1\"))\n",
        "        self.encoder.add(keras.layers.ReLU())\n",
        "        self.encoder.add(dense(1024, name=\"dL2\"))\n",
        "        self.encoder.add(keras.layers.ReLU())\n",
        "        self.encoder.add(dense(256, name=\"dL3\"))\n",
        "        self.encoder.add(keras.layers.ReLU())\n",
        "        self.encoder.add(dense(latent_num, name=\"encoded\"))\n",
        "\n",
        "        # decoder\n",
        "        self.decoder = keras.models.Sequential(name=\"decoder_net\")\n",
        "        self.decoder.add(keras.layers.Input(shape=(latent_num,)))\n",
        "        self.decoder.add(dense(256, name=\"gL1\"))\n",
        "        self.decoder.add(keras.layers.ReLU())\n",
        "        self.decoder.add(dense(1024, name=\"gL2\"))\n",
        "        self.decoder.add(keras.layers.ReLU())\n",
        "        self.decoder.add(dense(1024,  name=\"gL3\"))\n",
        "        self.decoder.add(keras.layers.ReLU())\n",
        "        self.decoder.add(dense(28*28,  name=\"decoded\"))\n",
        "        self.decoder.add(keras.layers.Reshape((28, 28), name=\"unflattened_decoded\"))\n",
        "\n",
        "        # discriminator \n",
        "        self.discriminator = keras.models.Sequential(name=\"discriminator_net\")\n",
        "        self.discriminator.add(keras.layers.Input(shape=(latent_num,)))\n",
        "        self.discriminator.add(keras.layers.Dropout(dropout))\n",
        "        self.discriminator.add(dense(1024, name=\"dL1\"))\n",
        "        self.discriminator.add(keras.layers.ReLU())\n",
        "        self.discriminator.add(keras.layers.Dropout(dropout))\n",
        "        self.discriminator.add(dense(1024, name=\"dL2\"))\n",
        "        self.discriminator.add(keras.layers.ReLU())\n",
        "        self.discriminator.add(keras.layers.Dropout(dropout))\n",
        "        self.discriminator.add(dense(256, name=\"dL3\"))\n",
        "        self.discriminator.add(keras.layers.ReLU())\n",
        "        self.discriminator.add(keras.layers.Dropout(dropout))\n",
        "        self.discriminator.add(dense(1, activation=\"sigmoid\", name=\"prob\"))\n",
        "\n",
        "        # reconstruction model\n",
        "        img_input = keras.layers.Input(shape=(28, 28))\n",
        "        encoded = self.encoder(img_input)\n",
        "        decoded = self.decoder(encoded)\n",
        "        self.autoencoder_model = keras.models.Model(name=\"autoencoder\",\n",
        "            inputs=img_input, outputs=decoded)\n",
        "        self.autoencoder_model.compile(optimizer=self.autoencoder_optimizer,\n",
        "                                    loss='mse')\n",
        "\n",
        "        # discriminator model\n",
        "        latents = keras.layers.Input(shape=(latent_num,))\n",
        "        self.discriminator_model = keras.models.Model(name=\"discriminator\",\n",
        "            inputs=latents, outputs=self.discriminator(latents))\n",
        "        self.discriminator_model.compile(optimizer=self.discriminator_optimizer,\n",
        "                                    loss='binary_crossentropy')\n",
        "        \n",
        "        # generator model\n",
        "        self.discriminator.trainable = False\n",
        "        self.generator_model = keras.models.Model(name=\"generator\",\n",
        "            inputs=img_input, outputs=self.discriminator(encoded))\n",
        "        self.generator_model.compile(optimizer=self.generator_optimizer,\n",
        "                                loss='binary_crossentropy')\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3Bto5ZZ3pPI",
        "colab_type": "text"
      },
      "source": [
        "#Manage scheduling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63se06Xj18dA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scheduling():\n",
        "    img_indices = np.arange(x_train.shape[0])\n",
        "    num_imgs = len(img_indices)\n",
        "    batch_num = num_imgs//batch_size\n",
        "\n",
        "    def noise(shape):\n",
        "        if gaussian_prior == True:\n",
        "            x = rng.normal(0,1, shape)\n",
        "        else:\n",
        "            x = rng.uniform(-1,1, shape)\n",
        "        return x\n",
        "\n",
        "    def get_test(dim):\n",
        "        x = np.linspace(-10, 10, dim)\n",
        "        X, Y = np.meshgrid(x, x)\n",
        "        return np.vstack((X.ravel(), Y.ravel())).T\n",
        "    test_dim = 16\n",
        "    test = get_test(test_dim)\n",
        "\n",
        "    return img_indices, batch_num, test, noise"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b60cKeX30bT",
        "colab_type": "text"
      },
      "source": [
        "#Init plots "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qDrfy1z3O-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output, display\n",
        "import matplotlib.gridspec as gridspec\n",
        "from PIL import Image\n",
        "import glob, io\n",
        "\n",
        "class Plotter:\n",
        "    def init_plots(self):\n",
        "        \n",
        "        self.count = 0\n",
        "\n",
        "        self.fig = plt.figure(figsize=(6,4.5), constrained_layout=True)\n",
        "        gs = self.fig.add_gridspec(3, 4)\n",
        "\n",
        "        ax1 = self.fig.add_subplot(gs[0,:])\n",
        "        self.rlossl, = ax1.plot(0,0, c=\"blue\")\n",
        "        self.dlossl, = ax1.plot(0,0, c=\"red\")\n",
        "        self.alossl, = ax1.plot(0,0, c=\"green\")\n",
        "        ax1.set_xlim([0, num_epochs])\n",
        "        ax1.set_ylim([0, rlim])\n",
        "\n",
        "        ax2 = self.fig.add_subplot(gs[1:,:2], aspect=\"equal\")\n",
        "        self.digits = ax2.imshow(np.zeros([2, 2]), vmin=-1, vmax=1)\n",
        "        ax2.set_axis_off()\n",
        "\n",
        "        ax3 = self.fig.add_subplot(gs[1:,2:], aspect=\"equal\")\n",
        "        cols = plt.cm.hsv(np.linspace(0, 1, 10))\n",
        "        self.points = []\n",
        "        for k in range(10):\n",
        "            self.points.append(ax3.scatter(0,0, color=cols[k], s=5, alpha=0.05))\n",
        "        ax3.set_xlim([-10, 10])\n",
        "        ax3.set_ylim([-10, 10])\n",
        "        self.fig.tight_layout()\n",
        "        clear_output()\n",
        "        display(plt.gcf())    \n",
        "\n",
        "    def update_plots(self, epoch, ae, data):\n",
        "\n",
        "        rloss, dloss, aloss, test = data\n",
        "\n",
        "        test_dim = int(np.sqrt(test.shape[0]))\n",
        "\n",
        "        self.rlossl.set_data(np.arange(epoch+1), np.hstack(rloss)*rlim)\n",
        "        self.dlossl.set_data(np.arange(epoch+1), dloss)\n",
        "        self.alossl.set_data(np.arange(epoch+1), aloss)\n",
        "\n",
        "        test_gen_batch = ae.decoder.predict(test).reshape(test_dim, test_dim, 28,28)\n",
        "        self.digits.set_data(np.vstack([ np.hstack([img for img in test_gen_row])\n",
        "            for test_gen_row in test_gen_batch[::-1]]))\n",
        "\n",
        "        test_latents = ae.encoder.predict(x_train)\n",
        "\n",
        "        for k in range(10):\n",
        "            digit_latents = test_latents[np.where(y_train==k)[0]]\n",
        "            self.points[k].set_offsets(digit_latents)\n",
        "\n",
        "        clear_output()\n",
        "        print(\"epoch: %-10d\\nrloss: %-10.7f  dloss: %-10.7f aloss: %-10.7f\" % (\n",
        "            epoch, rloss[-1], dloss[-1], aloss[-1]))\n",
        "        display(plt.gcf())\n",
        "\n",
        "        self.fig.savefig(\"aae-%06d.png\"%self.count)\n",
        "        self.count += 1\n",
        "\n",
        "        \n",
        "        # Open all the frames\n",
        "        image_names = sorted(glob.glob(\"aae*.png\"))\n",
        "        if len(image_names) > 1:\n",
        "            images = []\n",
        "\n",
        "            for img_name in image_names:\n",
        "                with open(img_name, \"rb\") as f:\n",
        "                    frame = Image.open(io.BytesIO(f.read()))\n",
        "                images.append(frame)\n",
        "            #save the frames as an animated GIF\n",
        "            images[0].save('aae.gif',\n",
        "                    save_all=True,\n",
        "                    append_images=images[1:],\n",
        "                    duration=500,\n",
        "                    loop=0)\n",
        "plotter = Plotter()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJYW6gn64KRE",
        "colab_type": "text"
      },
      "source": [
        "#Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj3ATQIfICsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run():\n",
        "\n",
        "    ae = Autoencoder(latent_num, dropout, w_stddev, \n",
        "                    autoencoder_rl, discriminator_rl, generator_rl)\n",
        "\n",
        "\n",
        "    plotter.init_plots()\n",
        "    img_indices, batch_num, test, noise = scheduling()\n",
        "\n",
        "    rloss = []\n",
        "    dloss = []\n",
        "    aloss = []\n",
        "    for epoch in range(num_epochs):\n",
        "        rng.shuffle(img_indices)\n",
        "        train_imgs = x_train[img_indices,...]\n",
        "        epoch_rloss = [] \n",
        "        epoch_dloss = [] \n",
        "        epoch_aloss = [] \n",
        "\n",
        "        for batch in range(batch_num):\n",
        "            \n",
        "            curr_rloss, curr_aloss, curr_dloss = [0, 0, 0]\n",
        "\n",
        "            real_images = train_imgs[batch*batch_size:(batch + 1)*batch_size]\n",
        "            \n",
        "            discr_batch_size = int(batch_size*batch_props[1])\n",
        "            gen_batch_size = int(batch_size*batch_props[2])\n",
        "            ae_batch_size = batch_size - (discr_batch_size + gen_batch_size)\n",
        "            \n",
        "            autoencoder_images = real_images[:ae_batch_size]\n",
        "            autoencoder_noise = ae_noise*rng.randn(*autoencoder_images.shape)\n",
        "\n",
        "            curr_rloss = ae.autoencoder_model.train_on_batch(\n",
        "                    autoencoder_images + autoencoder_noise,\n",
        "                    autoencoder_images)\n",
        "\n",
        "            adversarial_images = real_images[ae_batch_size:(ae_batch_size + discr_batch_size)] \n",
        "            adversarial_latents = ae.encoder.predict(adversarial_images)\n",
        "            prior_decay = 0*np.exp(-epoch/(num_epochs*2))\n",
        "            discriminator_latents = prior_std*(1 + prior_decay)*noise(adversarial_latents.shape) \n",
        "\n",
        "            curr_dloss = ae.discriminator_model.train_on_batch(\n",
        "                    np.vstack((discriminator_latents, adversarial_latents)), \n",
        "                    np.hstack((np.ones(discr_batch_size), np.zeros(discr_batch_size))))\n",
        "            \n",
        "            generator_images = real_images[discr_batch_size:(discr_batch_size + gen_batch_size)] \n",
        "            curr_aloss = ae.generator_model.train_on_batch(\n",
        "                generator_images, \n",
        "                np.ones(gen_batch_size))\n",
        "            \n",
        "            epoch_rloss.append(curr_rloss)\n",
        "            epoch_dloss.append(curr_dloss)\n",
        "            epoch_aloss.append(curr_aloss)\n",
        "            \n",
        "        rloss.append(np.mean(epoch_rloss))\n",
        "        dloss.append(np.mean(epoch_dloss))\n",
        "        aloss.append(np.mean(epoch_aloss))\n",
        "        \n",
        "        if epoch%epochs_to_show == 0 or epoch == (num_epochs - 1):    \n",
        "            plotter.update_plots(epoch, ae, [rloss, dloss, aloss, test])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QiXOVcB5v1FQ"
      },
      "source": [
        "#Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTwzGx1c2NdY",
        "colab_type": "code",
        "outputId": "5022d508-157b-4516-f440-5361dc3cec55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "cellView": "both"
      },
      "source": [
        "#@title\n",
        "dropout = 0.3\n",
        "ae_noise = 0.01\n",
        "latent_num = 2\n",
        "w_stddev = 0.1\n",
        "autoencoder_rl = 2e-4\n",
        "discriminator_rl = 2e-4\n",
        "generator_rl = 2e-4\n",
        "\n",
        "num_epochs  = 300\n",
        "batch_size = 300\n",
        "batch_props = [.33, .33, .33]\n",
        "epochs_to_show = 10\n",
        "gaussian_prior = True\n",
        "prior_std = 1.0\n",
        "\n",
        "rlim = 1\n",
        "\n",
        "print(\"\"\"\n",
        "dropout: {:}\n",
        "ae_noise: {:}\n",
        "latent_num: {:}\n",
        "w_stddev: {:}\n",
        "autoencoder_rl: {:2.0e}\n",
        "discriminator_rl: {:2.0e}\n",
        "generator_rl: {:2.0e}\n",
        "\n",
        "num_epochs: {:}  \n",
        "batch_size: {:}\n",
        "batch_props: {:}\n",
        "epochs_to_show: {:}\n",
        "gaussian_prior: {:}\n",
        "prior_std: {:6.4f}\n",
        "\"\"\".format(\n",
        "    dropout,\n",
        "    ae_noise,\n",
        "    latent_num,\n",
        "    w_stddev,\n",
        "    autoencoder_rl,\n",
        "    discriminator_rl,\n",
        "    generator_rl,\n",
        "    num_epochs,  \n",
        "    batch_size,\n",
        "    batch_props, \n",
        "    epochs_to_show, \n",
        "    gaussian_prior,\n",
        "    prior_std))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "dropout: 0.3\n",
            "ae_noise: 0.01\n",
            "latent_num: 2\n",
            "w_stddev: 0.1\n",
            "autoencoder_rl: 2e-04\n",
            "discriminator_rl: 2e-05\n",
            "generator_rl: 2e-05\n",
            "\n",
            "num_epochs: 300  \n",
            "batch_size: 300\n",
            "batch_props: [0.33, 0.33, 0.33]\n",
            "epochs_to_show: 10\n",
            "gaussian_prior: True\n",
            "prior_std: 1.0000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiBjHali3ubp",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "run()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}