# -*- coding: utf-8 -*-
"""GAN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WVcOHWZfTPbLzpySoZCCU5WmTUt2CB1O
"""

#!/usr/bin/env python
# -*- coding: utf-8 -*-

from __future__ import division, print_function, absolute_import

import numpy as np
import tensorflow as tf
import tensorflow.keras as keras

"""First we load the mnist dataset. We only need the images (from both the train and test set)
"""

from keras.datasets import mnist

(x_train, _), (x_test, _) = mnist.load_data()
x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.
x_train = 2*x_train -1
x_test = 2*x_test -1

"""#Build the graph
We build the GAN network. We make two Sequential models for the discriminator and the generator.
"""

from tensorflow.keras.optimizers import Adam

discriminator_optimizer = Adam(8e-5)
adversarial_optimizer = Adam(8e-5)
generator_optimizer = Adam(8e-5)

dropout = 0.3
latent_num = 100
w_stddev = 0.005

def w_init(stddev):
    return keras.initializers.RandomNormal(mean=0.0, stddev=stddev)

def dense(units, **kargs):
    return keras.layers.Dense(
        units=units,
        kernel_initializer=w_init(w_stddev),
        bias_initializer=w_init(w_stddev),
        **kargs)
                       
# discriminator 
discriminator = keras.models.Sequential(name="discriminator_net")
discriminator.add(keras.layers.Input(shape=(28,28)))
discriminator.add(keras.layers.Flatten(name="flattened_input"))
discriminator.add(keras.layers.Dropout(dropout))
discriminator.add(dense(units=1024, name="dL1"))
discriminator.add(keras.layers.ReLU())
discriminator.add(keras.layers.Dropout(dropout))
discriminator.add(dense(512, name="dL2"))
discriminator.add(keras.layers.ReLU())
discriminator.add(keras.layers.Dropout(dropout))
discriminator.add(dense(256, name="dL3"))
discriminator.add(keras.layers.ReLU())
discriminator.add(keras.layers.Dropout(dropout))
discriminator.add(dense(1, activation="sigmoid", name="prob"))

# generator
generator = keras.models.Sequential(name="generator_net")
generator.add(keras.layers.Input(shape=(latent_num,)))
generator.add(dense(256, name="gL1"))
generator.add(keras.layers.ReLU())
generator.add(dense(512, name="gL2"))
generator.add(keras.layers.ReLU())
generator.add(dense(1024,  name="gL3"))
generator.add(keras.layers.ReLU())
generator.add(dense(28*28,  name="output"))
generator.add(keras.layers.Reshape((28, 28), name="unflattened_output"))

input_images = discriminator.input
generated_patterns = generator.input

discriminator.trainable = True
generator.trainable = False
discriminator_model = keras.models.Model(name="discriminator",
    inputs=input_images, outputs=discriminator(input_images))
discriminator_model.compile(optimizer=discriminator_optimizer,
                            loss='binary_crossentropy')

discriminator.trainable = False
generator.trainable = True  
generated_images = generator(generated_patterns)
adversarial_model = keras.models.Model(name="adversarial",
    inputs=generated_patterns, outputs=discriminator(generated_images))
adversarial_model.compile(optimizer=adversarial_optimizer,
                          loss='binary_crossentropy')

generator_model = keras.models.Model(name="generator",
    inputs=generated_patterns, outputs=generated_images)
generator_model.compile(optimizer=generator_optimizer,
                        loss='binary_crossentropy')

discriminator.summary()
generator.summary()
discriminator_model.summary()
adversarial_model.summary()
generator_model.summary()

num_epochs  = 500
batch_size = 30
epochs_to_show = 2

img_indices = np.arange(x_train.shape[0])
num_imgs = len(img_indices)
batch_num = num_imgs//batch_size

def noise(size):
    x = np.random.normal(0,1, [size, latent_num])
    return x

noise_test = noise(25)

from IPython.display import clear_output
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
from PIL import Image
import glob, io


fig = plt.figure(figsize=(10,3), constrained_layout=True)
gs = fig.add_gridspec(1, 5)

ax1 = fig.add_subplot(gs[:,:-2])
dlossl, = ax1.plot(0,0, c="red")
glossl, = ax1.plot(0,0, c="green")
ax1.set_xlim([0, num_epochs])
ax1.set_ylim([0, 5])

ax2 = fig.add_subplot(gs[:,-2:], aspect="auto")
digits = ax2.imshow(np.zeros([2, 2]), vmin=-1, vmax=1)
ax2.set_axis_off()

dloss = []
aloss = []
count = 0
for epoch in range(num_epochs):
    np.random.shuffle(img_indices)
    train_imgs = x_train[img_indices,...]
    epoch_dloss = [] 
    epoch_aloss = [] 
    for batch in range(batch_num):
        real_images = train_imgs[batch*batch_size:(batch + 1)*batch_size]
        real_images_noise = 0.3*np.random.randn(*real_images.shape)
        adversarial_inputs = noise(batch_size)
        adversarial_images = generator_model.predict(adversarial_inputs)


        discriminator.trainable = True
        generator.trainable = False
        curr_dloss = discriminator_model.train_on_batch(
            np.vstack((real_images + real_images_noise, adversarial_images)), 
            np.hstack((np.ones(batch_size), np.zeros(batch_size))))

        discriminator.trainable = False
        generator.trainable = True   
        generator_inputs = noise(batch_size)
        curr_aloss = adversarial_model.train_on_batch(
            generator_inputs, 
            np.ones(batch_size))

        epoch_dloss.append(curr_dloss)
        epoch_aloss.append(curr_aloss)
        
    dloss.append(np.mean(epoch_dloss))
    aloss.append(np.mean(epoch_aloss))
    
    if epoch%epochs_to_show == 0 or epoch == (num_epochs - 1):

        clear_output()
        print("epoch: %d dloss: %-10.7f aloss: %-10.7f" % (
            epoch, dloss[-1], aloss[-1]))
        
        dlossl.set_data(np.arange(epoch+1), dloss)
        glossl.set_data(np.arange(epoch+1), aloss)

        test_gen_batch = generator_model.predict(noise_test).reshape(5,5,28,28)
        digits.set_data(np.vstack([ np.hstack([img for img in test_gen_row])
            for test_gen_row in test_gen_batch]))
        
        # plt.show()
        fig.savefig("gan-%06d.png"%count)
        count += 1

        # Open all the frames
        image_names = sorted(glob.glob("gan*.png"))
        if len(image_names) > 1:
            images = []

            for img_name in image_names:
                with open(img_name, "rb") as f:
                    frame = Image.open(io.BytesIO(f.read()))
                images.append(frame)
            #save the frames as an animated GIF
            images[0].save('gan.gif',
                    save_all=True,
                    append_images=images[1:],
                    duration=500,
                    loop=0)
